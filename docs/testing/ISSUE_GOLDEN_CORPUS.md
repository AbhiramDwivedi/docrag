# Issue: Create Golden Test Corpus and Deterministic Retrieval Test Harness

## Summary
Create a small, versioned golden test corpus and deterministic test harness so retrieval behavior is consistent across CI and local. This issue includes corpus design, artifact build script, tests, config, and CI wiring.

## Background
Current tests depend on local corpora that drift, causing inconsistent results. A hermetic, synthetic corpus with reproducible artifacts enables reliable regression testing and metrics.

## Deliverables
- tests/fixtures/corpus_v1/ (10–20 tiny files across formats; synthetic)
- tests/fixtures/queries_v1.jsonl (golden queries + expectations)
- scripts/build_test_artifacts.py (builds artifacts deterministically)
- tests/fixtures/artifacts_v1/ (generated: docmeta.db, vector.index, FTS5)
- config.test.yaml (deterministic settings pointing to artifacts)
- Unit, integration, and perf smoke tests
- CI job that builds/uses artifacts and runs tests

## Directory Layout
```
tests/
  fixtures/
    corpus_v1/
      text/
      office/
    queries_v1.jsonl
    artifacts_v1/           # generated by script (not committed)
scripts/
  build_test_artifacts.py
config.test.yaml
```

## Corpus v1 Design
- Entities: 8–10 proper nouns (companies, products, acronyms) with clear contexts
- Formats: txt, md, docx, pptx (1–2 slides), pdf (1 page), xlsx (single cell mention)
- Patterns: exact mentions, abbreviations, pluralization, near-duplicates, misspellings (for negative/edge cases), mentions inside bullets/tables
- Size: keep files tiny to keep artifacts small and fast

Recommended approach to avoid large binaries:
- Commit only txt/md; generate docx/pptx/pdf/xlsx during artifact build (via python-docx, python-pptx, reportlab, openpyxl)

Example corpus filenames (suggested):
- text/acme_overview.txt ("Acme is a data platform ...")
- text/bolt_spec.md (mentions BOLT v2.1)
- office/contoso_brief.docx (Acme and Contoso partnership)
- office/roadmap.pptx (slide bullet: "Integrate Reltora Gateway")
- office/onepager.pdf (paragraph mentioning Globex)
- office/metrics.xlsx (A1 cell: "Initech Q3")

## Golden Queries (tests/fixtures/queries_v1.jsonl)
Each line JSON object:
```
{"id":"q01","type":"entity","query":"what is Acme?","expects":{"doc_ids":["acme_overview.txt"],"k":20,"min_at_topk":1}}
{"id":"q02","type":"keyword","query":"find files containing Globex","expects":{"doc_ids":["onepager.pdf"],"k":20,"min_at_topk":1}}
{"id":"q03","type":"abbr","query":"what is BOLT?","expects":{"doc_ids":["bolt_spec.md"],"k":20,"min_at_topk":1}}
```
- Keep expectations minimal (presence in top-k) to avoid brittle score assertions.

## Determinism Requirements
- Pin embedding model: sentence-transformers/all-MiniLM-L6-v2 (initial)
- Force CPU; set seeds (python, numpy, torch)
- Normalize vectors; use cosine similarity; stable tie-break by (score desc, id asc)
- Ensure SQLite FTS5 available; if unavailable, skip lexical tests with a clear marker

## config.test.yaml (example)
```
retrieval:
  k: 100
  mmr_lambda: 0.5
  similarity_threshold: 0.3
hybrid:
  enabled: true
  dense_weight: 0.6
  lexical_weight: 0.4
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  normalize: true
  use_cosine: true
paths:
  data_root: "tests/fixtures/artifacts_v1"
```

## Build Script: scripts/build_test_artifacts.py
Responsibilities:
- Optionally generate office binaries (docx, pptx, pdf, xlsx) into tests/fixtures/corpus_v1/office
- Compute checksum over corpus_v1 content and settings to detect drift
- Clean and rebuild artifacts into tests/fixtures/artifacts_v1/
- Ingest corpus → chunk → embed (CPU, seeds set) → build FAISS (IndexFlatIP with normalized vectors) → build FTS5 (chunks_fts)
- Emit metadata.json with: checksum, model name, dim, index type, build time, package versions

CLI flags:
- --rebuild (force clean build)
- --fail-on-drift (exit non-zero if checksum mismatch vs cached metadata)
- --ci (stricter logs and deterministic modes)

Implementation notes:
- Use numpy seed + torch.manual_seed; set OMP_NUM_THREADS=1 for stability
- Verify FTS5 availability (SELECT sqlite_version(), PRAGMA compile_options); skip lexical index if absent, but return a clear status
- Store chunk IDs stable and sort outputs deterministically

## Tests to Add
Unit tests:
- tests/test_embeddings_norm.py: vectors normalized; cosine conversion correct
- tests/test_mmr.py: MMR selection correctness on toy vectors
- tests/test_fts5.py: FTS5 index creation and simple query (skip if not available)
- tests/test_hybrid_merge.py: score normalization and dedupe

Integration tests:
- tests/test_golden_retrieval.py:
  - Load config.test.yaml via env var (e.g., DOC_RAG_CONFIG)
  - Ensure build_test_artifacts.py has been run (or run in setup)
  - For each JSONL entry, assert at least one expected doc appears in top-k
  - Verify keyword queries route to lexical path (assert flag/log marker)

Perf smoke:
- tests/test_perf_smoke.py: p95 latency bound (generous, e.g., <2.5s) and artifact size check

## CI Wiring (GitHub Actions example)
```
name: tests
on: [push, pull_request]
jobs:
  golden:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          pip install -e backend[test]
          pip install pysqlite3-binary || true
      - name: Cache artifacts
        uses: actions/cache@v4
        with:
          path: tests/fixtures/artifacts_v1
          key: artifacts-${{ hashFiles('tests/fixtures/corpus_v1/**', 'scripts/build_test_artifacts.py', 'config.test.yaml', 'backend/**') }}
      - name: Build artifacts
        run: |
          python scripts/build_test_artifacts.py --rebuild --ci
      - name: Run tests
        env:
          DOC_RAG_CONFIG: config.test.yaml
        run: |
          pytest -q
```

## Tasks
- [ ] Create folder structure: tests/fixtures/corpus_v1 and tests/fixtures/artifacts_v1
- [ ] Author synthetic text/md files; implement generation of office binaries in build script
- [ ] Add queries file tests/fixtures/queries_v1.jsonl (entity, keyword, abbr, edge cases)
- [ ] Implement scripts/build_test_artifacts.py (rebuild, checksum, deterministic build)
- [ ] Add config.test.yaml with pinned model and deterministic settings
- [ ] Add unit tests (normalization, MMR, FTS5, hybrid merge)
- [ ] Add integration tests (top-k presence; lexical routing)
- [ ] Add perf smoke tests (latency bound, artifact size)
- [ ] Add CI job as above; ensure FTS5 available or skip impacted tests
- [ ] Update README with instructions to run: build script + pytest using config.test.yaml

## Acceptance Criteria
- CI runs tests using only the golden corpus artifacts; no access to local corpora
- Queries in queries_v1.jsonl consistently return expected chunks in top-k on CI and locally
- Artifacts are reproducible (checksum validated) and metadata recorded
- Documentation exists for regenerating artifacts and running tests locally

## Out of Scope
- Embedding model upgrades (covered elsewhere)
- Large corpora and production-scale performance
